{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4185294,"sourceType":"datasetVersion","datasetId":2466264},{"sourceId":6122531,"sourceType":"datasetVersion","datasetId":3509534},{"sourceId":8168526,"sourceType":"datasetVersion","datasetId":4833924},{"sourceId":8209981,"sourceType":"datasetVersion","datasetId":4865254}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import os\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim\nfrom torchvision import datasets, transforms, models\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:42:03.785592Z","iopub.execute_input":"2024-07-23T14:42:03.785946Z","iopub.status.idle":"2024-07-23T14:42:09.066146Z","shell.execute_reply.started":"2024-07-23T14:42:03.785917Z","shell.execute_reply":"2024-07-23T14:42:09.065154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:43:11.479629Z","iopub.execute_input":"2024-07-23T14:43:11.480199Z","iopub.status.idle":"2024-07-23T14:43:11.508109Z","shell.execute_reply.started":"2024-07-23T14:43:11.480169Z","shell.execute_reply":"2024-07-23T14:43:11.507019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading & Preprocessing","metadata":{}},{"cell_type":"code","source":"train_folder = \"/kaggle/input/real-and-fake-image-create-by-ai/MyDataset/train\"\nval_folder = \"/kaggle/input/real-and-fake-image-create-by-ai/MyDataset/test\"\nepochs = 100\nlr = 0.003","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:43:14.656162Z","iopub.execute_input":"2024-07-23T14:43:14.656866Z","iopub.status.idle":"2024-07-23T14:43:14.661011Z","shell.execute_reply.started":"2024-07-23T14:43:14.656834Z","shell.execute_reply":"2024-07-23T14:43:14.660072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare Datasets","metadata":{}},{"cell_type":"markdown","source":"Ela filter","metadata":{}},{"cell_type":"code","source":"class ELAFilter:\n    def __init__(self, quality=90):\n        self.quality = quality\n\n    def __call__(self, img):\n        # Convert torch tensor to numpy array (H, W, C) and scale to [0, 255]\n        img_np = img.permute(1, 2, 0).numpy() * 255.0\n        img_np = img_np.astype(np.uint8)\n\n        # Save the image at the specified quality level\n        _, compressed_image = cv2.imencode('.jpg', img_np, [int(cv2.IMWRITE_JPEG_QUALITY), self.quality])\n        compressed_image = cv2.imdecode(compressed_image, 1)\n\n        # Calculate the ELA image (absolute difference)\n        ela_image = np.abs(img_np - compressed_image)\n\n        # Normalize ELA to the range [0, 1]\n        # ela_image = ela_image.astype(np.float32) / 255.0\n        #print(ela_image)\n        # Convert ELA back to torch tensor\n        ela_tensor = torch.tensor(ela_image).permute(2, 0, 1).float()  # Convert to (C, H, W) and float type\n\n        return ela_tensor","metadata":{"execution":{"iopub.status.busy":"2024-07-20T12:25:53.473228Z","iopub.execute_input":"2024-07-20T12:25:53.473897Z","iopub.status.idle":"2024-07-20T12:25:53.482781Z","shell.execute_reply.started":"2024-07-20T12:25:53.473861Z","shell.execute_reply":"2024-07-20T12:25:53.481673Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define transforms\ntransform_resnet = transforms.Compose([\n    transforms.Resize(256),  # Resize to a size a bit larger than required, helps with random cropping\n    transforms.CenterCrop(224),  # Center crop to the required size (224x224)\n    transforms.ToTensor(),  # Convert to tensor\n    ])\nval_transform_resnet = transforms.Compose([\n    transforms.Resize(256),  # Resize to a size a bit larger than required, helps with random cropping\n    transforms.CenterCrop(224),  # Center crop to the required size (224x224)\n    transforms.ToTensor(),  # Convert to tensor\n   ])\n\n# Load dataset\nfull_data = datasets.ImageFolder(root=train_folder, transform=transform_resnet)\n\nval_data = datasets.ImageFolder(root=val_folder, transform=val_transform_resnet)\n\n# Define train-test split ratio\ntrain_size = int(0.7 * len(full_data))\ntest_size = len(full_data) - train_size\n\n# Split the dataset\ntrain_data, test_data = torch.utils.data.random_split(full_data, [train_size, test_size])\n\n# Create DataLoader for each dataset\nbatch_size = 128\ntrain_loader = DataLoader(train_data, batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size, shuffle=False)\nval_loader = DataLoader(val_data, batch_size, shuffle=False)\n\n# Print number of samples in each split\nprint(f'Training samples: {len(train_data)}')\nprint(f'Testing samples: {len(test_data)}')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:43:17.469399Z","iopub.execute_input":"2024-07-23T14:43:17.470264Z","iopub.status.idle":"2024-07-23T14:43:58.592114Z","shell.execute_reply.started":"2024-07-23T14:43:17.470229Z","shell.execute_reply":"2024-07-23T14:43:58.591179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(full_data.classes)\nprint(val_data.classes)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:44:34.277735Z","iopub.execute_input":"2024-07-23T14:44:34.278082Z","iopub.status.idle":"2024-07-23T14:44:34.282660Z","shell.execute_reply.started":"2024-07-23T14:44:34.278057Z","shell.execute_reply":"2024-07-23T14:44:34.281751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"testing dataloaders with 5 random photos","metadata":{}},{"cell_type":"code","source":"i = 0\nfor i, (images, labels) in enumerate(train_loader, 0):  # Assuming train_loader gives a batch of images and labels\n    if i >= 5:\n        break\n    \n    # Access the first image in the batch and permute dimensions\n    image = images[0].permute(1, 2, 0)\n    \n    # Display the image\n    plt.imshow(image)\n    plt.title(\"fake\" if labels[0] == 0 else \"real\")\n    plt.show()\n    \n    i += 1","metadata":{"execution":{"iopub.status.busy":"2024-07-22T09:06:18.725651Z","iopub.execute_input":"2024-07-22T09:06:18.726497Z","iopub.status.idle":"2024-07-22T09:06:54.681400Z","shell.execute_reply.started":"2024-07-22T09:06:18.726465Z","shell.execute_reply":"2024-07-22T09:06:54.680383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training/Validation Methods","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport gc\n# Training loop\ndef train_model(model, criterion, optimizer, dataloaders, classification_layer,finetuning_lr,num_epochs=10):\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n            \n            running_loss = 0.0\n            running_corrects = 0\n            \n            # Use tqdm to wrap the dataloader\n            phase_dataloader = tqdm(dataloaders[phase], desc=phase)\n            for inputs, labels in phase_dataloader:\n                inputs = inputs.to(device)\n                labels = labels.to(device).float().unsqueeze(1)\n                \n                # Zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # Forward\n                if phase == \"train\":\n                    if epoch >= 0.8 * num_epochs:\n                        # Unfreeze all layers for fine-tuning\n                        for param in model.parameters():\n                            param.requires_grad = True\n                        optimizer.param_groups[0]['lr'] = finetuning_lr\n                        save_model(model, \"earlystop\" + model._get_name(), (0,0))\n                    else:\n                        # Freeze the CNN part\n                        for param in model.parameters():\n                            param.requires_grad = False\n                        # Unfreeze the classification layer\n                        for param in classification_layer.parameters():\n                            param.requires_grad = True\n                elif phase == \"val\":\n                    for param in model.parameters():\n                            param.requires_grad = False\n\n                        \n                outputs = model(inputs)\n                preds = torch.sigmoid(outputs)\n                preds = (preds > 0.5).float()\n                loss = criterion(outputs, labels)\n\n                # Backward + optimize only if in training phase\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n                \n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            \n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n            \n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n            \n            # Clear cache after each epoch\n            torch.cuda.empty_cache()\n            del inputs, labels\n            gc.collect()\n        \n        print()\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-07-22T09:09:21.929148Z","iopub.execute_input":"2024-07-22T09:09:21.929791Z","iopub.status.idle":"2024-07-22T09:09:21.943170Z","shell.execute_reply.started":"2024-07-22T09:09:21.929761Z","shell.execute_reply":"2024-07-22T09:09:21.942221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport torch\nfrom tqdm import tqdm\n\ndef test_model(model, dataloader, criterion, device):\n    model.eval()  # Set model to evaluation mode\n    running_loss = 0.0\n    all_labels = []\n    all_preds = []\n\n    with torch.no_grad():\n        val_dataloader = tqdm(dataloader, desc=\"validation\")\n        for inputs, labels in val_dataloader:\n            inputs = inputs.to(device)\n            labels = labels.to(device).float().unsqueeze(1)\n            outputs = model(inputs)\n            \n\n            preds = (torch.sigmoid(outputs) > 0.5) * 1\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * inputs.size(0)\n            all_labels.append(labels)\n            all_preds.append(preds)\n\n    # Move all predictions and labels to CPU once\n    all_labels = torch.cat(all_labels).cpu().numpy()\n    all_preds = torch.cat(all_preds).cpu().numpy()\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds)\n    recall = recall_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds)\n\n    print(f'Test Loss: {epoch_loss:.4f}')\n    print(f'Accuracy: {accuracy:.4f}')\n    print(f'Precision: {precision:.4f}')\n    print(f'Recall: {recall:.4f}')\n    print(f'F1 Score: {f1:.4f}')\n\n    return epoch_loss, accuracy, precision, recall, f1\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T12:32:23.363376Z","iopub.execute_input":"2024-07-22T12:32:23.363785Z","iopub.status.idle":"2024-07-22T12:32:23.907058Z","shell.execute_reply.started":"2024-07-22T12:32:23.363746Z","shell.execute_reply":"2024-07-22T12:32:23.906183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save/Load Methods","metadata":{}},{"cell_type":"code","source":"import datetime as dt\ndef save_model(model, model_name,model_evaluation_history):\n    model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n    # Define the string date format.\n    # Get the current Date and Time in a DateTime Object.\n    # Convert the DateTime object to string according to the style mentioned in date_time_format string.\n    date_time_format = '%Y_%m_%d__%H_%M_%S'\n    current_date_time_dt = dt.datetime.now()\n    current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n\n    # Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n    model_file_name = f'{model_name}___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.pth'\n\n    # Save your Model.\n    torch.save(model.state_dict(), f'{model_file_name}_entire_dict')\n    torch.save(model, f'{model_file_name}_entire')\n\ndef load_model(model_path):\n    # Load the object from the file\n    loaded_model = torch.load(model_path)\n    loaded_model.eval()\n    \n    \n    return loaded_model","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:44:46.251349Z","iopub.execute_input":"2024-07-23T14:44:46.252045Z","iopub.status.idle":"2024-07-23T14:44:46.258681Z","shell.execute_reply.started":"2024-07-23T14:44:46.252012Z","shell.execute_reply":"2024-07-23T14:44:46.257676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Models Training","metadata":{}},{"cell_type":"markdown","source":"### **EfficientNet Training**","metadata":{}},{"cell_type":"code","source":"\nmodel = efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\ndataloaders = {'train' : train_loader, 'val' : test_loader}\ndevice = \"cuda\"\n# Modify the classifier to fit the binary classification problem\nnum_features = model.classifier.fc.in_features\nmodel.classifier.fc = nn.Linear(num_features, 1)  # Output layer for binary classification\n\n# Move the model to the appropriate device\nmodel = model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy loss with logits\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nmodel = train_model(model, criterion, optimizer, dataloaders, model.classifier.fc ,10e-6)\n\nepoch_loss, accuracy, precision, recall, f1 = test_model(model, val_loader, criterion, device)\n\nsave_model(model, \"efficientnet-B0\", (epoch_loss, accuracy))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **ResNet Training**","metadata":{}},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\n# model = load_model(\"ResNet-50(NEW_DS)___Date_Time_2024_07_20__17_19_24___Loss_0___Accuracy_0.pth_entire\")\ndataloaders = {'train' : train_loader, 'val' : test_loader}\ndevice = \"cuda\"\n# Modify the classifier to fit the binary classification problem\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 1)  # Output layer for binary classification\n\n# Move the model to the appropriate device\nmodel = model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy loss with logits\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nmodel = train_model(model, criterion, optimizer, dataloaders,model.fc ,10e-6, num_epochs=10)\n\n# epoch_loss, accuracy, precision, recall, f1 = test_model(model, val_loader, criterion, device)\n\nsave_model(model, \"ResNet-50\", (0, 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **ResNext**","metadata":{}},{"cell_type":"code","source":"# Define the dataloaders\ndataloaders = {'train': train_loader, 'val': test_loader}\n\n# Set device to GPU if available\ndevice = torch.device(\"cuda\")\n\n# Load the ResNeXt model with pretrained weights\nmodel = models.resnext50_32x4d(pretrained=True)\n\n# Modify the classifier to fit the binary classification problem\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 1)  # Output layer for binary classification\n\n# Move the model to the appropriate device\nmodel = model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy loss with logits\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel = train_model(model, criterion, optimizer, dataloaders, model.fc, 10e-6, num_epochs=8)\n\nsave_model(model, \"resnext50_32x4d\", (0, 0))\nepoch_loss, accuracy, precision, recall, f1 = test_model(model, val_loader, criterion, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **ConvNext**","metadata":{}},{"cell_type":"code","source":"# Define the dataloaders\ndataloaders = {'train': train_loader, 'val': test_loader}\n\n# Set device to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the ConvNeXt model with pretrained weights\nmodel = models.convnext_base(pretrained=True)\n\n# Modify the classifier to fit the binary classification problem\nnum_features = model.classifier[2].in_features\nmodel.classifier[2] = nn.Linear(num_features, 1)  # Output layer for binary classification\n\n# Move the model to the appropriate device\nmodel = model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy loss with logits\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel = train_model(model, criterion, optimizer, dataloaders, model.classifier[2], 10e-6, num_epochs=8)\n\nsave_model(model, \"convnext_base\", (0, 0))\nepoch_loss, accuracy, precision, recall, f1 = test_model(model, val_loader, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T09:48:56.526497Z","iopub.execute_input":"2024-07-22T09:48:56.527110Z","iopub.status.idle":"2024-07-22T11:38:43.848864Z","shell.execute_reply.started":"2024-07-22T09:48:56.527080Z","shell.execute_reply":"2024-07-22T11:38:43.847773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model(\"/kaggle/working/convnext 7epochs___Date_Time_2024_07_22__12_12_52___Loss_0___Accuracy_0.pth_entire\")\ncriterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy loss with logits\ntest_model(model, val_loader, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T12:33:51.920440Z","iopub.execute_input":"2024-07-22T12:33:51.920985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **VGG**","metadata":{}},{"cell_type":"code","source":"# Define the dataloaders\ndataloaders = {'train': train_loader, 'val': test_loader}\n\n# Set device to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the VGG model with pretrained weights\nmodel = models.vgg16(pretrained=True)\n\n# Modify the classifier to fit the binary classification problem\nnum_features = model.classifier[6].in_features\nmodel.classifier[6] = nn.Linear(num_features, 1)  # Output layer for binary classification\n\n# Move the model to the appropriate device\nmodel = model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy loss with logits\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nmodel = train_model(model, criterion, optimizer, dataloaders, model.classifier[6], 10e-6)\n\nepoch_loss, accuracy, precision, recall, f1 = test_model(model, val_loader, criterion, device)\n\nsave_model(model, \"vgg16\", (epoch_loss, accuracy))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Output Visualization**","metadata":{}},{"cell_type":"code","source":"class GradCAM:\n    def __init__(self, model, target_layer):\n        self.model = model\n        self.target_layer = target_layer\n        self.gradients = None\n        self.features = None\n\n        self.hook_layers()\n\n    def hook_layers(self):\n        def forward_hook(module, input, output):\n            self.features = output\n        def backward_hook(module, grad_input, grad_output):\n            self.gradients = grad_output[0]\n        self.target_layer.register_forward_hook(forward_hook)\n        self.target_layer.register_backward_hook(backward_hook)\n\n    def get_cam_weights(self):\n        return torch.mean(self.gradients, dim=(2, 3), keepdim=True)\n\n    def generate_heatmap(self, features):\n        weights = self.get_cam_weights()\n        weighted_sum = (weights * features).sum(dim=1, keepdim=True)\n        heatmap = weighted_sum.relu()\n        heatmap = F.interpolate(heatmap, size=(224, 224), mode='bilinear', align_corners=False)\n        heatmap = heatmap.squeeze().cpu().detach().numpy()\n        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n        return heatmap\n\n    def __call__(self, img_tensor, target_class):\n        self.model.zero_grad()\n        output = self.model(img_tensor)\n        pred = (torch.sigmoid(output) > 0.5) * 1\n        print(pred.data)\n        print(\"fake\" if pred == 0 else \"real\")\n        target = torch.zeros_like(output)\n        target[0][target_class] = 1\n        output.backward(gradient=target)\n        heatmap = self.generate_heatmap(self.features)\n        return heatmap\n\ndef overlay_heatmap(image, heatmap, alpha=0.6, colormap=cv2.COLORMAP_JET):\n    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), colormap)\n    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    overlayed_image = heatmap * alpha + np.array(image) * (1 - alpha)\n    return np.uint8(overlayed_image)\n\ndef overlay_heatmap(image, heatmap, alpha=0.6, colormap=cv2.COLORMAP_JET):\n    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), colormap)\n    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    overlayed_image = heatmap * alpha + np.array(image) * (1 - alpha)\n    return np.uint8(overlayed_image)\n\ndef preprocess_image(img_path):\n    img = Image.open(img_path)\n    img_tensor = val_transform_resnet(img).unsqueeze(0).to(device)\n    img_tensor.requires_grad = True\n    return img_tensor, img\n\n\ndef generate_gradcam(model, target_layer, img_path):\n    # Preprocess image\n    img_tensor, img = preprocess_image(img_path)\n\n    # Initialize Grad-CAM\n    grad_cam = GradCAM(model, target_layer)\n\n    # Forward pass\n    output = model(img_tensor)\n    target_class = output.argmax().item()\n\n    # Generate heatmap\n    heatmap = grad_cam(img_tensor, target_class)\n\n    # Superimpose heatmap on the original image\n    img_np = np.array(img.resize((224, 224)))\n    overlayed_img = overlay_heatmap(img_np, heatmap)\n\n    # Display the image\n    plt.figure(figsize=(10, 10))\n    plt.imshow(overlayed_img)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:44:51.106571Z","iopub.execute_input":"2024-07-23T14:44:51.107218Z","iopub.status.idle":"2024-07-23T14:44:51.126397Z","shell.execute_reply.started":"2024-07-23T14:44:51.107187Z","shell.execute_reply":"2024-07-23T14:44:51.125434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#artifacts model\nmodel = load_model(\"/kaggle/working/ResNet-50___Date_Time_2024_07_21__02_33_27___Loss_0___Accuracy_0.pth_entire\")\n\n#no artifacts model\n# model = load_model(\"/kaggle/working/ResNet-50___Date_Time_2024_07_20__02_19_55___Loss_0___Accuracy_0.pth_entire\")\n\n# print(model)\n# target_layer = model.features[7][0].block[0]\ntarget_layer = model.layer4[-1]\nimg_path = '/kaggle/input/real-and-fake-image-create-by-ai/MyDataset/test/fake/20220902_080648_4384bb7429cc43a5bd8796f8755674eb.png'\n\ngenerate_gradcam(model, target_layer, img_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T15:51:13.226220Z","iopub.execute_input":"2024-07-23T15:51:13.227221Z","iopub.status.idle":"2024-07-23T15:51:13.671151Z","shell.execute_reply.started":"2024-07-23T15:51:13.227185Z","shell.execute_reply":"2024-07-23T15:51:13.670122Z"},"trusted":true},"execution_count":null,"outputs":[]}]}